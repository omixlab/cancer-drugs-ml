import argparse
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
from sklearn.model_selection import GridSearchCV
import pickle 
from sklearn.svm import SVC 

CLASSIFIERS_PARAMS = [
    ('GradientBoostingClassifier', GradientBoostingClassifier(), {'max_depth': range(1, 21), 'n_estimators': range(10, 201, 10)}),
    ('RandomForestClassifier', RandomForestClassifier(), {'max_depth': range(1, 21)}),
    #('SVC', SVC(),{'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})
    ]

def train_model(preprocess_csv, output_model, train_test_split_percent=0.25, grid_search_scoring='f1'):
    df = pd.read_csv(preprocess_csv)
    X = df.drop(['ACTIVITY'], axis=1)
    y = df['ACTIVITY']
    X_train, X_test, y_train, y_test = train_test_split(X, y)
    best_model = None 
    best_score = 0 
    for model_name, model, params in CLASSIFIERS_PARAMS:
        print("testing model", model_name, '...')
        grid_search = GridSearchCV(model, params, scoring = grid_search_scoring)
        grid_search.fit(X_train, y_train)
        if grid_search.best_score_ > best_score: 
            best_model = grid_search.best_estimator_
            best_score = grid_search.best_score_
    best_model.fit(X_train, y_train)
    y_pred = best_model.predict(X_test)
    report = classification_report(y_test, y_pred)
    print(report)
    with open(output_model, 'wb') as writer:
        pickle.dump(best_model, writer)
    return None

def main(): 
    argument_parser = argparse.ArgumentParser()
    argument_parser.add_argument('--preprocess_csv', required=True, help='file generated by bambu-preprocess')
    argument_parser.add_argument('--output_model', required=True, help='path to output model')
    argument_parser.add_argument('--train_test_split_percent', default=0.25, type=float, help='percent of the train/test split')
    argument_parser.add_argument('--grid_search_scoring', default='f1', choices=['accuracy', 'recall', 'precision', 'f1', 'roc_auc'])
    arguments = argument_parser.parse_args()
    train_model(preprocess_csv=arguments.preprocess_csv, output_model=arguments.output_model, train_test_split_percent=arguments.train_test_split_percent, grid_search_scoring=arguments.grid_search_scoring)

if __name__=="__main__":
    main()


