import argparse
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier
from sklearn.model_selection import RandomizedSearchCV 
import pickle 
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier 
import numpy as np 
import json

CLASSIFIERS_PARAMS = [
    ('GradientBoostingClassifier', GradientBoostingClassifier(), {'max_depth': range(1, 21), 'n_estimators': range(10, 201, 10)}),
    ('RandomForestClassifier', RandomForestClassifier(), {'max_depth': range(1, 21)}),
    ('SVC', SVC(),{'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}),
    ('DecisionTreeClassifier', DecisionTreeClassifier(), {'max_depth': range(1, 21), 'criterion': ['gini', 'entropy']}),
    ('ExtraTreesClassifier', ExtraTreesClassifier(), {'max_depth': range(1, 21)}),
    ]

def train_model(preprocess_train_csv, preprocess_test_csv, output_model, train_test_split_percent=0.25, grid_search_scoring='f1'):

    df_train = pd.read_csv(preprocess_train_csv)
    df_train = df_train.astype(np.float32)
    X_train = df_train.drop(['ACTIVITY'], axis=1)
    X_train = np.nan_to_num(X_train)
    y_train = df_train['ACTIVITY']

    df_test = pd.read_csv(preprocess_test_csv)
    df_test = df_test.astype(np.float32)
    X_test = df_test.drop(['ACTIVITY'], axis=1)
    X_test = np.nan_to_num(X_test)
    y_test = df_test['ACTIVITY']

    best_model = None 
    best_score = 0 
    for model_name, model, params in CLASSIFIERS_PARAMS:

        print("testing model", model_name, '...')

        grid_search = RandomizedSearchCV(model, params, scoring = grid_search_scoring, n_jobs=4, verbose=10)
        grid_search.fit(X_train, y_train)
        grid_search.best_estimator_.fit(X_train, y_train)
        y_pred = grid_search.best_estimator_.predict(X_test)
        report = classification_report(y_test, y_pred, output_dict=True)

        with open(output_model + f'.{model_name}.train.json', 'w') as writer:
            writer.write(json.dumps(report))

        model = grid_search.best_estimator_
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        report = classification_report(y_test, y_pred, output_dict=True)

        with open(output_model + f'.{model_name}.test.json', 'w') as writer:
            writer.write(json.dumps(report))

        if grid_search.best_score_ > best_score: 
            best_model = grid_search.best_estimator_
            best_score = grid_search.best_score_

    best_model.fit(X_train, y_train)
    y_pred = best_model.predict(X_test)
    report = classification_report(y_test, y_pred, output_dict=True)

    with open(output_model, 'wb') as writer:
        pickle.dump(best_model, writer)
    
    with open(output_model + '.best.json', 'w') as writer:
        writer.write(json.dumps(report))
    
    return None

def main(): 
    argument_parser = argparse.ArgumentParser()
    argument_parser.add_argument('--preprocess_train_csv', required=True, help='train CSV file generated by bambu-preprocess')
    argument_parser.add_argument('--preprocess_test_csv', required=True, help='test CSV file generated by bambu-preprocess')
    argument_parser.add_argument('--output_model', required=True, help='path to output model')
    argument_parser.add_argument('--train_test_split_percent', default=0.25, type=float, help='percent of the train/test split')
    argument_parser.add_argument('--grid_search_scoring', default='roc_auc', choices=['accuracy', 'recall', 'precision', 'f1', 'roc_auc'])
    arguments = argument_parser.parse_args()
    train_model(preprocess_train_csv=arguments.preprocess_train_csv, preprocess_test_csv=arguments.preprocess_test_csv, output_model=arguments.output_model, train_test_split_percent=arguments.train_test_split_percent, grid_search_scoring=arguments.grid_search_scoring)

if __name__=="__main__":
    main()


